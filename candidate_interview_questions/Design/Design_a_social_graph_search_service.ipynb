{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Social graph search service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definitions\n",
    "\n",
    "\n",
    "\n",
    "100 million users\n",
    "\n",
    "50 friends per user average, a very asymetric distrubution with a long tail on the high side\n",
    "\n",
    "some searches will be much more frequent than others\n",
    "\n",
    "1 billion friend searches per month\n",
    "\n",
    "relationships are unweighted\n",
    "\n",
    "## claculations\n",
    "\n",
    "5 billion friend relationships, 100M * 50\n",
    "\n",
    "2.5 millions seconds per month, 1B/2.5M = 400 searches per second\n",
    "\n",
    "## componants\n",
    "\n",
    "- client\n",
    "\n",
    "- web-server\n",
    "\n",
    "- search API\n",
    "\n",
    "- user graph service\n",
    "\n",
    "- user store\n",
    "\n",
    "\n",
    "To scale this service, we need to add a load balancer in front of our web-server, we need to make the other back-end componants horizontally scalable, and the data-stores need to also be horizontally scalable, with replication.  \n",
    "\n",
    "The client and web-server will need to support other functionality, and user store will likely be usedd by other services as well.\n",
    "\n",
    "## the search service\n",
    "\n",
    "Since our graph is unweighted, we need to use some version of BFS to find the shortest path from the start the the destination user.  We can speed up our search a little bit by searching from both directions iteratively, with seperate queues, iterating on the queue which is the smallest first, and checking if each elements of the shortest queue is in the other queue.  We save time here by choosing to search the smaller queue first.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Person(object):\n",
    "\n",
    "    def __init__(self, id, name, friend_ids):\n",
    "        self.id = id\n",
    "        self.name = name\n",
    "        self.friend_ids = friend_ids # set\n",
    "\n",
    "class PersonServer(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.people = {}  # key: person_id, value: person\n",
    "\n",
    "    def add_person(self, person):\n",
    "        ...\n",
    "\n",
    "    def people(self, ids):\n",
    "        results = []\n",
    "        for id in ids:\n",
    "            if id in self.people:\n",
    "                results.append(self.people[id])\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class BFSer:\n",
    "    \n",
    "    def __init__(self, start_node):\n",
    "        self.start_node = start_node\n",
    "        self.queue = deque()\n",
    "        self.paths = {}\n",
    "        self.queue_hash = set() # for the other searcher to check\n",
    "        \n",
    "    def step(self, path):\n",
    "        return None\n",
    "\n",
    "class Graph:\n",
    "    \n",
    "    def __init__(self, person_service):\n",
    "        self.person_service = person_service\n",
    "\n",
    "    def shortest_path(self, source, dest):\n",
    "        return None\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
