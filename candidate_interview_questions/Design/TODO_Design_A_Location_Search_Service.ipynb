{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Given a latitude and longitude, provide the N Closest locaitons\n",
    "\n",
    "Design a service that can be queried with a latitude and longitude, and return the N closest locations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scope\n",
    "\n",
    "### users\n",
    "\n",
    "Lets assume this is for google maps, so 1 Billion+ Monthly active users\n",
    "\n",
    "### use-cases\n",
    "\n",
    "- what is a location?\n",
    "(city, town, place of interest, ...), lets assume any of these.\n",
    "\n",
    "- how do we define closeness?\n",
    "in the simple case, we'll call it euclidian distance, but we could use something like manhattan distance/route-finding to determine distance as well.  Let's abstract the distance function for now, but treat it like euclidean distance.\n",
    "\n",
    "- how do users use this\n",
    "--given my position, give me the closest locations\n",
    "--given a locations position, give me the closest locations\n",
    "-given a random position, give me the closest locations\n",
    "\n",
    "- additional functionality\n",
    "We can discuss it later.\n",
    "\n",
    "\n",
    "#### capacity\n",
    "- back of envelope calculations\n",
    "\n",
    "- reads/s\n",
    "1 Billion active users / month\n",
    "2.5 million sec/month\n",
    "4000 reads / sec (avg) * (avg user reads / month)\n",
    "\n",
    "- writes/s\n",
    "\n",
    "writes are generated internally when new locations are added / locations are updated.  We can assume something like 10,000 new locations a month.\n",
    "\n",
    "Additionally, we could allow for user based writes to locations, but this would require a security service, reviewers.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## high-level architecture\n",
    "\n",
    "- client\n",
    "- DNS/router\n",
    "- load-balancer/router\n",
    "- web-server (possibly shared)\n",
    "- service endpoint\n",
    "\n",
    "read-service & write service\n",
    "\n",
    "\n",
    "\n",
    "- data layer (including caching)\n",
    "\n",
    "\n",
    "\n",
    "everything down to the web-server should be handeled by maps.google.com, since it already exists, and we're just providing them a microservice.\n",
    "\n",
    "We may already have a locations DB from maps, and we can create a truncated locations DB for our use.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Service endpoint\n",
    "\n",
    "We've defined our use-case as returning the N closest points, but there are similar use cases.  So we've defined a read only end-point with a single get command.  So we can define an endpoint that only responds to //gets\n",
    "\n",
    "The 'get(latitude, longitude, N)' will take in two, optionally 3 values. N would represent the number of locations to return.\n",
    "\n",
    "The response should be a ordered list of responses\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## componant design\n",
    "\n",
    "### OO design\n",
    "\n",
    "\n",
    "#### objects\n",
    "\n",
    "- locations\n",
    "\n",
    "public:\n",
    "\n",
    "getLocation(id), returns : location\n",
    "\n",
    "candidate_locations_getter(pos), returns : [locations]\n",
    "\n",
    "location_filter(pos, n, locations), returns: [locations]\n",
    "\n",
    "- tiles\n",
    "\n",
    "tile_getter_obj\n",
    "\n",
    "getTile(pos), returns [tile]\n",
    "\n",
    "getTilesWithNLocations(pos, N), returns : [tiles]\n",
    "\n",
    "looks up ids with tileHashService\n",
    "\n",
    "- tileHash\n",
    "\n",
    "encode()\n",
    "decode()\n",
    "\n",
    "update()\n",
    "\n",
    "- locationGetter\n",
    "\n",
    "getNLocations(pos, n), returns [locations]\n",
    "\n",
    "- locationWriter\n",
    "\n",
    "writeLocation(location)\n",
    "\n",
    "bulkWriteLocation([locations])\n",
    "\n",
    "public:\n",
    "\n",
    "\n",
    "\n",
    "location_writer(location)\n",
    "\n",
    "bulk_location_writer([locations])\n",
    "\n",
    "private:\n",
    "\n",
    "\n",
    "- DB design\n",
    "\n",
    "- precision\n",
    "\n",
    "we need to decide some level of baseline precision for our request lat/long.  Our request should come in with the highest precision of GPS data available to it (clicking on a zoomed out map, not very precise, GPS locator on phone, very precise).  We should define our baseline precision.\n",
    "\n",
    "The first step of a request will be to apply this truncation.\n",
    "\n",
    "- Storage\n",
    "\n",
    "Our storage strucutre will be highly coupled to our search strategy.  In 2D, we can tile our word along lat. and long.  The tiles will be stored with keys that are 2-D hashed \n",
    "\n",
    "- Tiles\n",
    "\n",
    "(lat_block_idx, long_block_idx), neighbors, num_locations, [(location_ids, (lat., long))]\n",
    "\n",
    "For each request, we should return 6 tiles, the hit-tile (where the requested position is) and the five sourounding tiles.\n",
    "\n",
    "If the sum of their \"num_locations\" is greater than or equal to N, we collect all of the locations in the tiles and run through the locations in the 6 tiles, and collect the N closest with our distance function.  we can do this with a sort, or a priority queue and one pass.\n",
    "\n",
    "- locations\n",
    "Our locations table will be a NoSQL K-V type DB, allowing for complex schema, varying types\n",
    "\n",
    "(location_id, meta_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bottlenecks\n",
    "\n",
    "Writes are somewhat trivial, so bottlenecks will be mostly be in read.  There will be periodicity in read volume across locations, and locations should have seperate caches.  Horizontal scaling, automatic scaling, and location specific caching should handle most of  this.  As far as prior knowledge of scaling requirements, we can get a lot of that info from historic maps.google traffic.\n",
    "\n",
    "\n",
    "### maintaining hash-bin consistancy\n",
    "\n",
    "hash-bins will only get smaller, and only when we do writes.  We should try to maintain our tile size so that they have a consistant number of locaitons within them.  If N is fixed, this may be a good number, but we should assume N could change.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
