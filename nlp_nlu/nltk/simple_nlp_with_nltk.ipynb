{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /__ / .__/\\_,_/_/ /_/\\_\\   version 1.6.0\n",
      "      /_/\n",
      "\n",
      "Using Python version 2.7.10 (default, Jul 13 2015 12:05:58)\n",
      "SparkContext available as sc, HiveContext available as sqlContext.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "#%load_ext autoreload\n",
    "#%autoreload 2\n",
    "%reload_ext autoreload\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math, sys, os\n",
    "from numpy.random import randn\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "# setup pyspark for IPython_notebooks\n",
    "spark_home = os.environ.get('SPARK_HOME', None)\n",
    "sys.path.insert(0, spark_home + \"/python\")\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python/lib/py4j-0.8.2.1-src.zip'))\n",
    "execfile(os.path.join(spark_home, 'python/pyspark/shell.py'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nltk niceties\n",
    "\n",
    "the 'nltk.text.Text' class\n",
    "\n",
    "concordance:  finding a word with some context from a document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 11 of 11 matches:\n",
      "ong the former , one was of a most monstrous size . ... This came towards us , \n",
      "ON OF THE PSALMS . \" Touching that monstrous bulk of the whale or ork we have r\n",
      "ll over with a heathenish array of monstrous clubs and spears . Some were thick\n",
      "d as you gazed , and wondered what monstrous cannibal and savage could ever hav\n",
      "that has survived the flood ; most monstrous and most mountainous ! That Himmal\n",
      "they might scout at Moby Dick as a monstrous fable , or still worse and more de\n",
      "th of Radney .'\" CHAPTER 55 Of the Monstrous Pictures of Whales . I shall ere l\n",
      "ing Scenes . In connexion with the monstrous pictures of whales , I am strongly\n",
      "ere to enter upon those still more monstrous stories of them which are to be fo\n",
      "ght have been rummaged out of this monstrous cabinet there is no telling . But \n",
      "of Whale - Bones ; for Whales of a monstrous size are oftentimes cast up dead u\n"
     ]
    }
   ],
   "source": [
    "text1.concordance(\"monstrous\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "similar words based on context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imperial subtly impalpable pitiable curious abundant perilous\n",
      "trustworthy untoward singular lamentable few determined maddens\n",
      "horrible tyrannical lazy mystifying christian exasperate\n"
     ]
    }
   ],
   "source": [
    "text1.similar(\"monstrous\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".common_context : of two or more words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_pretty is_pretty a_lucky am_glad be_glad\n"
     ]
    }
   ],
   "source": [
    "text2.common_contexts([\"monstrous\", \"very\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".dispersion: the location of words in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# text4.dispersion_plot([\"citizens\", \"democracy\", \"freedom\", \"duties\", \"America\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple metrics:\n",
    "\n",
    "diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def lexical_diversity(text):\n",
    "    return len(text) / len(set(text))\n",
    "\n",
    "def percentage(count, total):\n",
    "    return 100 * count / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Accessing data from the web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from BeautifulSoup import BeautifulSoup          # For processing HTML\n",
    "#from BeautifulSoup import BeautifulStoneSoup     # For processing XML\n",
    "#import BeautifulSoup                             # To get everything\n",
    "from urllib import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'str'>\n",
      "1176896\n",
      "The Project Gutenberg EBook of Crime and Punishment, by Fyodor Dostoevsky\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "url = \"http://www.gutenberg.org/files/2554/2554.txt\"\n",
    "raw = urlopen(url).read()\n",
    "print type(raw)\n",
    "print len(raw)\n",
    "print raw[:75]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tokenizing with library tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'list'>\n",
      "254352\n",
      "['The', 'Project', 'Gutenberg', 'EBook', 'of', 'Crime', 'and', 'Punishment', ',', 'by']\n"
     ]
    }
   ],
   "source": [
    "tokens = nltk.word_tokenize(raw)\n",
    "print type(tokens)\n",
    "print len(tokens)\n",
    "print tokens[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convert to nltk.text.Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'nltk.text.Text'>\n",
      "['AND', 'PUNISHMENT', 'PART', 'I', 'CHAPTER', 'I', 'On', 'an', 'exceptionally', 'hot', 'evening', 'early', 'in', 'July', 'a', 'young', 'man', 'came', 'out', 'of', 'the', 'garret', 'in', 'which', 'he', 'lodged', 'in', 'S.', 'Place', 'and', 'walked', 'slowly', ',', 'as', 'though', 'in', 'hesitation', ',', 'towards', 'K.']\n",
      "Katerina Ivanovna; Pyotr Petrovitch; Pulcheria Alexandrovna; Avdotya\n",
      "Romanovna; Rodion Romanovitch; Marfa Petrovna; Sofya Semyonovna; old\n",
      "woman; Project Gutenberg-tm; Porfiry Petrovitch; Amalia Ivanovna;\n",
      "great deal; Nikodim Fomitch; young man; Ilya Petrovitch; n't know;\n",
      "Project Gutenberg; Dmitri Prokofitch; Andrey Semyonovitch; Hay Market\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "text = nltk.Text(tokens)\n",
    "print type(text)\n",
    "print text[1020:1060]\n",
    "print text.collocations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting HTML and scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!doctype html public \"-//W3C//DTD HTML 4.0 Transitional//EN\n",
      "[u'>', u'<', u'a', u'href=', u\"''\", u'http', u':', u'//www.bbc.co.uk/whereilive/', u\"''\", u'class=', u\"''\", u'bbcpageWhite', u\"''\", u'>', u'WHERE', u'&', u'nbsp', u';', u'I', u'&', u'nbsp', u';', u'LIVE', u'<', u'/a', u'>', u'<', u'/b', u'>', u'<', u'/font', u'>', u'<', u'/td', u'>', u'&', u'nbsp', u';', u'&', u'nbsp', u';', u'A-Z', u'INDEX', u'&', u'nbsp', u';', u'&', u'nbsp', u';', u'&', u'nbsp', u';', u'SEARCH', u'&', u'nbsp', u';', u'<', u'td', u'>', u'<', u'img', u'src=', u\"''\", u'/shared/img/o.gif', u\"''\", u'width=', u\"''\", u'42', u\"''\", u'height=', u\"''\", u'1', u\"''\", u'alt=', u\"''\", u\"''\", u'/', u'>', u'<', u'/td', u'>', u'end', u'news', u'toolbar', u'1.0END', u'OF', u'BANNER', u'&', u'nbsp', u';', u'You', u'are', u'in', u':', u'&', u'nbsp', u';', u'Health', u'&', u'nbsp', u';', u'News', u'Front', u'PageAfricaAmericasAsia-PacificEuropeMiddle', u'EastSouth', u'AsiaUKBusinessEntertainmentScience/NatureTechnologyHealthMedical', u'notes', u'--', u'--', u'--', u'--', u'--', u'--', u'-Talking', u'Point', u'--', u'--', u'--', u'--', u'--', u'--', u'-Country', u'ProfilesIn', u'Depth', u'--', u'--', u'--', u'--', u'--', u'--', u'-Programmes', u'--', u'--', u'--', u'--', u'--', u'--', u'-SERVICESDaily', u'E-mailNews', u'TickerMobile/PDAs', u'--', u'--', u'--', u'--', u'--', u'--', u'-Text', u'OnlyFeedbackHelpEDITIONSChange', u'to', u'UKFriday', u',', u'27', u'September', u',', u'2002', u',', u'11:51', u'GMT', u'12:51', u'UKBlondes', u\"'to\", u'die', u'out', u'in', u'200', u\"years'Scientists\", u'believe', u'the', u'last', u'blondes', u'will', u'be', u'in', u'FinlandThe', u'last', u'natural', u'blondes', u'will', u'die', u'out', u'within', u'200', u'years', u',', u'scientists', u'believe.A', u'study', u'by', u'experts', u'in', u'Germany', u'suggests', u'people', u'with', u'blonde', u'hair', u'are', u'an', u'endangered', u'species', u'and', u'will', u'become', u'extinct', u'by', u'2202.Researchers', u'predict', u'the', u'last', u'truly', u'natural', u'blonde', u'will', u'be', u'born', u'in', u'Finland', u'-', u'the', u'country', u'with', u'the', u'highest', u'proportion', u'of', u'blondes.GENInlineBOXGENInlineQUOTEThe', u'frequency', u'of', u'blondes', u'may', u'drop', u'but', u'they', u'wo', u\"n't\", u'disappearGENInlineNAMEProf', u'Jonathan', u'Rees', u',', u'University', u'of', u'EdinburghBut', u'they', u'say', u'too', u'few', u'people', u'now', u'carry', u'the', u'gene', u'for', u'blondes', u'to', u'last', u'beyond', u'the', u'next', u'two', u'centuries.The', u'problem', u'is', u'that', u'blonde', u'hair', u'is', u'caused', u'by', u'a', u'recessive', u'gene.In', u'order', u'for', u'a', u'child', u'to', u'have', u'blonde', u'hair', u',', u'it', u'must', u'have', u'the', u'gene', u'on', u'both', u'sides', u'of', u'the', u'family', u'in', u'the', u'grandparents', u\"'\", u'generation.Dyed', u'rivalsThe', u'researchers', u'also', u'believe', u'that', u'so-called', u'bottle']\n"
     ]
    }
   ],
   "source": [
    "url = \"http://news.bbc.co.uk/2/hi/health/2284783.stm\"\n",
    "html = urlopen(url).read()\n",
    "print html[:60]\n",
    "soup = BeautifulSoup(html) # BeautifulSoup class\n",
    "raw = soup.getText()\n",
    "tokens = nltk.word_tokenize(raw)\n",
    "print tokens[96:399]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
