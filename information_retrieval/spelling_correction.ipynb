{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edit distance\n",
    "\n",
    "Edit distance between two sequences (s1,s2) is the number of edit operations required to transform s1 into s2.  There are three main operations that can be performed.\n",
    "\n",
    "1. Insert an element into s1\n",
    "2. Remove an element from s1\n",
    "3. replace element x in s1 with element y\n",
    "\n",
    "The literature name for this metric is *Levenshtein distance*, which is the total number of these operations requried to transform s1 into s2.  \n",
    "\n",
    "This metric can be generalized to apply different weights to different operations.  Either different weights between the three operations above, or different weights depending on the actual element's likelihood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The computationally expensive approach to this operation requres O(|s1| * |s2|)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "def levenshtein_matrix(s1,s2):\n",
    "    n, m = len(s1), len(s2)\n",
    "    if n > m:\n",
    "        s1,s2 = s2,s1\n",
    "        n,m = m,n\n",
    "    M = [[0 for i in range(m+1)] for j in range(n+1)]\n",
    "    for i in range(n+1):\n",
    "        M[i][0] = i\n",
    "    for j in range(m+1):\n",
    "        M[0][j] = j\n",
    "    # double for loops reveals complexity\n",
    "    for i in range(1, n+1):\n",
    "        for j in range(1, m+1):\n",
    "            M[i][j] = min(M[i-1][j-1] + (0 if s1[i-1]==s2[j-1] else 1),\n",
    "                          M[i-1][j] + 1,\n",
    "                          M[i][j-1] + 1)\n",
    "    return M[m][n]\n",
    "\n",
    "\n",
    "def levenshtein(s1,s2):\n",
    "    n, m = len(s1), len(s2)\n",
    "    if n > m:\n",
    "        s1,s2 = s2,s1\n",
    "        n,m = m,n\n",
    "        \n",
    "    current = range(n+1)\n",
    "    # double for loops reveals complexity\n",
    "    for i in range(1, m+1):\n",
    "        previous, current = current, [i] + [0 for x in range(n)]\n",
    "        for j in range(1,n+1):\n",
    "            add, delete = previous[j]+1, current[j-1]+1\n",
    "            change = previous[j-1]\n",
    "            if s1[j-1] != s2[i-1]:\n",
    "                change = change + 1\n",
    "            current[j] = min(add, delete, change)\n",
    "            \n",
    "    return current[n]\n",
    "\n",
    "\n",
    "s1 = \"fast\"\n",
    "s2 = \"cats\"\n",
    "\n",
    "print levenshtein(s1, s2)\n",
    "print levenshtein_matrix(s1, s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course doing a 1xN comparison of a query term with vocabulary terms is expensive.  So, it is impractical to simply score all vocabulary terms.  \n",
    "\n",
    "More efficient approaches involve reducing the set of possible vocabulary words over which to search using intelligent indexing, such as permuterm indexing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## n-gram indexes\n",
    "\n",
    "A statistical approach to reducing the vocabulary over which edit distances need be computed uses n-gram indexes.  This involves computing n-grams over a training set, and using this context information to identify probable words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
