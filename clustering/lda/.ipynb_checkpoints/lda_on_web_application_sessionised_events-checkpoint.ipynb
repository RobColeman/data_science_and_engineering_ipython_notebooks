{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Dirichlet Allocation on Web-App events\n",
    "\n",
    "LDA is a clustering model often applied to topic modeling.  Roughly LDA uses a graphical model of nested multinomials to destribe the distribution of tokens (words) within topics, and topics within documents.  \n",
    "\n",
    "Gaphics for the model's mathematics is left as a TODO.  For now [LDA Wikipedia Article](https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation).\n",
    "\n",
    "However, this nested multinomial structure can be applied to other settings as well.  In this case, if we are interested in clustering behavior withing a web-application. If we are minitoring unique events within the application, and we assume that users of the application come to the app with some underlaying purpose for each session (uninterupted period of use) in the application (the cardinality of total purposes for sessions being much smaller than that of events), we can cluster sesssions by event frequency the same way we would cluster documents by word frequency.  Structurally, the session-event model can be equivilent to the topic-word model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sessions\n",
    "\n",
    "For this experiment, events were sessionized by glomming together events that occured within 90min of each other; except sessions were not allowed to exceed 24hours in length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Online-LDA\n",
    "\n",
    "import sys, re, time, string\n",
    "import numpy as n\n",
    "from scipy.special import gammaln, psi\n",
    "\n",
    "n.random.seed(100000001)\n",
    "meanchangethresh = 0.001\n",
    "\n",
    "def dirichlet_expectation(alpha):\n",
    "    \"\"\"\n",
    "    For a vector theta ~ Dir(alpha), computes E[log(theta)] given alpha.\n",
    "    \"\"\"\n",
    "    if (len(alpha.shape) == 1):\n",
    "        return(psi(alpha) - psi(n.sum(alpha)))\n",
    "    return(psi(alpha) - psi(n.sum(alpha, 1))[:, n.newaxis])\n",
    "\n",
    "def parse_sessions_list(sessions, event_set):\n",
    "\n",
    "    D = len(sessions)\n",
    "    \n",
    "    eventsids = list()\n",
    "    eventscts = list()\n",
    "    for D in range(0, D):\n",
    "        events = sessions[D]\n",
    "        ddict = dict()\n",
    "        for e in events:\n",
    "            if (e in event_set):\n",
    "                eventtoken = event_set[e]\n",
    "                if (not eventtoken in ddict):\n",
    "                    ddict[eventtoken] = 0\n",
    "                ddict[eventtoken] += 1\n",
    "        eventsids.append(ddict.keys())\n",
    "        eventscts.append(ddict.values())\n",
    "\n",
    "    return((eventsids, eventscts))\n",
    "\n",
    "class OnlineLDA:\n",
    "    \"\"\"\n",
    "    Implements online VB for LDA as described in (Hoffman et al. 2010).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, event_set, K, D, alpha = None, eta = None, tau0 = 1024, kappa = 0.7):\n",
    "        self._events = dict()\n",
    "        for events in event_set:\n",
    "            events = events.lower()\n",
    "            self._events[events] = len(self._events)\n",
    "\n",
    "        self._K = K\n",
    "        self._W = len(self._events)\n",
    "        self._D = D\n",
    "        self._alpha = alpha if alpha else 1.0 / K\n",
    "        self._eta = eta if eta else 1.0 / K\n",
    "        self._tau0 = tau0 + 1\n",
    "        self._kappa = kappa\n",
    "        self._updatect = 0\n",
    "\n",
    "        # Initialize the variational distribution q(beta|lambda)\n",
    "        self._lambda = 1 * n.random.gamma(100.0, 1.0 / 100.0, (self._K, self._W))\n",
    "        self._Elogbeta = dirichlet_expectation(self._lambda)\n",
    "        self._expElogbeta = n.exp(self._Elogbeta)\n",
    "\n",
    "    def update_lambda(self, sessions):\n",
    "\n",
    "        # rhot will be between 0 and 1, and says how much to weight\n",
    "        # the information we got from this mini-batch.\n",
    "        rhot = pow(self._tau0 + self._updatect, -self._kappa)\n",
    "        self._rhot = rhot\n",
    "        # Do an E step to update gamma, phi | lambda for this\n",
    "        # mini-batch. This also returns the information about phi that\n",
    "        # we need to update lambda.\n",
    "        (gamma, sstats) = self.do_e_step(sessions)\n",
    "        # Estimate held-out likelihood for current values of lambda.\n",
    "        bound = self.approx_bound(sessions, gamma)\n",
    "        # Update lambda based on documents.\n",
    "        self._lambda = self._lambda * (1-rhot) + \\\n",
    "            rhot * (self._eta + self._D * sstats / len(sessions))\n",
    "        self._Elogbeta = dirichlet_expectation(self._lambda)\n",
    "        self._expElogbeta = n.exp(self._Elogbeta)\n",
    "        self._updatect += 1\n",
    "\n",
    "        return(gamma, bound)\n",
    "\n",
    "    def approx_bound(self, sessions, gamma):\n",
    "        # This is to handle the case where someone just hands us a single\n",
    "        # document, not in a list.\n",
    "        if (type(sessions).__name__ == 'string'):\n",
    "            temp = list()\n",
    "            temp.append(sessions)\n",
    "            sessions = temp\n",
    "\n",
    "        (eventsids, eventscts) = parse_sessions_list(sessions, self._events)\n",
    "        batchD = len(sessions)\n",
    "\n",
    "        score = 0\n",
    "        Elogtheta = dirichlet_expectation(gamma)\n",
    "        expElogtheta = n.exp(Elogtheta)\n",
    "\n",
    "        # E[log p(sessions | theta, id)]\n",
    "        for d in range(0, batchD):\n",
    "            gammad = gamma[d, :]\n",
    "            ids = eventsids[d]\n",
    "            cts = n.array(eventscts[d])\n",
    "            phinorm = n.zeros(len(ids))\n",
    "\n",
    "            for i in range(0, len(ids)):\n",
    "                temp = Elogtheta[d, :] + self._Elogbeta[:, ids[i]]\n",
    "                tmax = max(temp)\n",
    "                phinorm[i] = n.log(sum(n.exp(temp - tmax))) + tmax\n",
    "            score += n.sum(cts * phinorm)\n",
    "\n",
    "        # E[log p(theta | alpha) - log q(theta | gamma)]\n",
    "        score += n.sum((self._alpha - gamma)*Elogtheta)\n",
    "        score += n.sum(gammaln(gamma) - gammaln(self._alpha))\n",
    "        score += sum(gammaln(self._alpha*self._K) - gammaln(n.sum(gamma, 1)))\n",
    "\n",
    "        # Compensate for the subsampling of the population of documents\n",
    "        score = score * self._D / len(sessions)\n",
    "\n",
    "        # E[log p(beta | eta) - log q (beta | lambda)]\n",
    "        score = score + n.sum((self._eta-self._lambda)*self._Elogbeta)\n",
    "        score = score + n.sum(gammaln(self._lambda) - gammaln(self._eta))\n",
    "        score = score + n.sum(gammaln(model._eta*model._W) - \n",
    "                              gammaln(n.sum(model._lambda, 1)))\n",
    "\n",
    "        return (score)\n",
    "\n",
    "\n",
    "    def do_e_step(self, sessions):\n",
    "        # This is to handle the case where someone just hands us a single\n",
    "        # document, not in a list.\n",
    "        if (type(sessions).__name__ == 'string'):\n",
    "            temp = list()\n",
    "            temp.append(sessions)\n",
    "            sessions = temp\n",
    "\n",
    "        (eventsids, eventscts) = parse_sessions_list(sessions, self._events)\n",
    "        batchD = len(sessions)\n",
    "\n",
    "        # Initialize the variational distribution q(theta|gamma) for\n",
    "        # the mini-batch\n",
    "        gamma = 1*n.random.gamma(100., 1./100., (batchD, self._K))\n",
    "        Elogtheta = dirichlet_expectation(gamma)\n",
    "        expElogtheta = n.exp(Elogtheta)\n",
    "\n",
    "        sstats = n.zeros(self._lambda.shape)\n",
    "        # Now, for each document d update that document's gamma and phi\n",
    "        it = 0\n",
    "        meanchange = 0\n",
    "        for d in range(0, batchD):\n",
    "            # These are mostly just shorthand (but might help cache locality)\n",
    "            ids = eventsids[d]\n",
    "            cts = eventscts[d]\n",
    "            gammad = gamma[d, :]\n",
    "            Elogthetad = Elogtheta[d, :]\n",
    "            expElogthetad = expElogtheta[d, :]\n",
    "            expElogbetad = self._expElogbeta[:, ids]\n",
    "            # The optimal phi_{dwk} is proportional to \n",
    "            # expElogthetad_k * expElogbetad_w. phinorm is the normalizer.\n",
    "            phinorm = n.dot(expElogthetad, expElogbetad) + 1e-100\n",
    "            # Iterate between gamma and phi until convergence\n",
    "            for it in range(0, 100):\n",
    "                lastgamma = gammad\n",
    "                # We represent phi implicitly to save memory and time.\n",
    "                # Substituting the value of the optimal phi back into\n",
    "                # the update for gamma gives this update. Cf. Lee&Seung 2001.\n",
    "                gammad = self._alpha + expElogthetad * \\\n",
    "                    n.dot(cts / phinorm, expElogbetad.T)\n",
    "                Elogthetad = dirichlet_expectation(gammad)\n",
    "                expElogthetad = n.exp(Elogthetad)\n",
    "                phinorm = n.dot(expElogthetad, expElogbetad) + 1e-100\n",
    "                # If gamma hasn't changed much, we're done.\n",
    "                meanchange = n.mean(abs(gammad - lastgamma))\n",
    "                if (meanchange < meanchangethresh):\n",
    "                    break\n",
    "            gamma[d, :] = gammad\n",
    "            # Contribution of document d to the expected sufficient\n",
    "            # statistics for the M step.\n",
    "            sstats[:, ids] += n.outer(expElogthetad.T, cts/phinorm)\n",
    "\n",
    "        # This step finishes computing the sufficient statistics for the\n",
    "        # M step, so that\n",
    "        # sstats[k, w] = \\sum_d n_{dw} * phi_{dwk} \n",
    "        # = \\sum_d n_{dw} * exp{Elogtheta_{dk} + Elogbeta_{kw}} / phinorm_{dw}.\n",
    "        sstats = sstats * self._expElogbeta\n",
    "\n",
    "        return((gamma, sstats))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ServerSelectionTimeoutError",
     "evalue": "10.0.3.43:27017: [Errno 64] Host is down",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mServerSelectionTimeoutError\u001b[0m               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-b0b4a0696320>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mbatchsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# The total number of documents in Wikipedia\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmongo_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_session_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;31m# The number of topics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/rcoleman/rob/code/python/data_science_ipython_notebooks/clustering/lda/mongo_client.py\u001b[0m in \u001b[0;36mget_session_count\u001b[0;34m(project_id)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0msessions_collection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMongoClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmongo_ip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmongo_port\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmongo_db_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msession_collection_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mcursor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msessions_collection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/2.7.10_2/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pymongo/cursor.pyc\u001b[0m in \u001b[0;36mcount\u001b[0;34m(self, with_limit_and_skip)\u001b[0m\n\u001b[1;32m    672\u001b[0m                 \u001b[0mcmd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"skip\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__skip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__collection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdistinct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/2.7.10_2/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pymongo/collection.pyc\u001b[0m in \u001b[0;36m_count\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    983\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;34m\"\"\"Internal count helper.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_socket_for_reads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslave_ok\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m             res = self._command(sock_info, cmd, slave_ok,\n\u001b[1;32m    987\u001b[0m                                 allowable_errors=[\"ns missing\"])\n",
      "\u001b[0;32m/usr/local/Cellar/python/2.7.10_2/Frameworks/Python.framework/Versions/2.7/lib/python2.7/contextlib.pyc\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/2.7.10_2/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pymongo/mongo_client.pyc\u001b[0m in \u001b[0;36m_socket_for_reads\u001b[0;34m(self, read_preference)\u001b[0m\n\u001b[1;32m    697\u001b[0m         \u001b[0mtopology\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_topology\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0msingle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtopology\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopology_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTOPOLOGY_TYPE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSingle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mread_preference\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msock_info\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m             slave_ok = (single and not sock_info.is_mongos) or (\n\u001b[1;32m    701\u001b[0m                 preference != ReadPreference.PRIMARY)\n",
      "\u001b[0;32m/usr/local/Cellar/python/2.7.10_2/Frameworks/Python.framework/Versions/2.7/lib/python2.7/contextlib.pyc\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/2.7.10_2/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pymongo/mongo_client.pyc\u001b[0m in \u001b[0;36m_get_socket\u001b[0;34m(self, selector)\u001b[0m\n\u001b[1;32m    661\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcontextlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontextmanager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 663\u001b[0;31m         \u001b[0mserver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_topology\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_server\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    664\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__all_credentials\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msock_info\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/2.7.10_2/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pymongo/topology.pyc\u001b[0m in \u001b[0;36mselect_server\u001b[0;34m(self, selector, server_selection_timeout, address)\u001b[0m\n\u001b[1;32m    119\u001b[0m         return random.choice(self.select_servers(selector,\n\u001b[1;32m    120\u001b[0m                                                  \u001b[0mserver_selection_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m                                                  address))\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     def select_server_by_address(self, address,\n",
      "\u001b[0;32m/usr/local/Cellar/python/2.7.10_2/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pymongo/topology.pyc\u001b[0m in \u001b[0;36mselect_servers\u001b[0;34m(self, selector, server_selection_timeout, address)\u001b[0m\n\u001b[1;32m     95\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mserver_timeout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mnow\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mend_time\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m                     raise ServerSelectionTimeoutError(\n\u001b[0;32m---> 97\u001b[0;31m                         self._error_message(selector))\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_opened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mServerSelectionTimeoutError\u001b[0m: 10.0.3.43:27017: [Errno 64] Host is down"
     ]
    }
   ],
   "source": [
    "import cPickle, string, numpy, getopt, sys, random, time, re, pprint\n",
    "\n",
    "import mongo_client\n",
    "from bson import ObjectId\n",
    "\n",
    "project_id = \"517eda23c82561f72a000005\"\n",
    "\n",
    "# The number of documents to analyze each k\n",
    "batchsize = 500\n",
    "# The total number of documents in Wikipedia\n",
    "D = mongo_client.get_session_count(project_id)\n",
    "# The number of topics\n",
    "K = 6\n",
    "\n",
    "event_set = mongo_client.get_events_ids_by_project_id(project_id)\n",
    "W = len(event_set)\n",
    "model = onlineldavb.OnlineLDA(event_set, K, D)\n",
    "\n",
    "for k, (n_skip,n_limit) in enumerate(build_batches(n, batch_size)):\n",
    "\n",
    "    sessions = mongo_client.get_sessions_batch(project_id, n_skip, n_limit)\n",
    "        \n",
    "    (gamma, bound) = model.update_lambda(sessions)\n",
    "\n",
    "    (event_tokens, event_counts) = onlineldavb.parse_sessions_list(sessions, model._event_set)\n",
    "    pereventsbound = bound * len(sessions) / (D * sum(map(sum, event_counts)))\n",
    "\n",
    "    print '%d:  rho_t = %f,  held-out perplexity estimate = %f' % \\\n",
    "        (k, model._rhot, numpy.exp(-pereventsbound))\n",
    "\n",
    "    if (k % 10 == 0):\n",
    "        numpy.savetxt('lambda-%d.dat' % k, model._lambda)\n",
    "        numpy.savetxt('gamma-%d.dat' % k, gamma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
