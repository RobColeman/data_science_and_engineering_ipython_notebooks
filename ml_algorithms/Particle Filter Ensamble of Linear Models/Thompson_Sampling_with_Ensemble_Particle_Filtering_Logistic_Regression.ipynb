{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thompson Sampling\n",
    "\n",
    "Thompson Sampling has been show, academically, to outperform all other approaches on the contextual-bandit problem.  The approach does so by performing exploration over which it has less confidence, while being fairly greedy over parameters with high confidence.\n",
    "\n",
    "<img src=\"thompsonsamplingdescwiki.png\">\n",
    "\n",
    "where bayes rule says:\n",
    "\n",
    "So, Thompson sampling requires a predictive model that computes the posterior distribution over the model parameters given the data, so that it may sample from this distribution at each action step.\n",
    "\n",
    "As per bayes rule the posterior distribution over model parameters is:\n",
    "\n",
    "<img src=\"bayes_rule_proportional.png\">\n",
    "\n",
    "The three components of this equation are, the posterior distribution on the left of the equation, the likelihood function in the center, and the prior on the right.\n",
    "\n",
    "Although this looks simple, what makes this hard for most algorithms is that even though you can easily compute P(theta_i | Data), the posterior probability of a particular parameter vector, finding the best theta_i would require knowing the whole P(theta | Data).  \n",
    "\n",
    "Many algorithms, including the LR versions we currently are testing, approximate solving ArgMax_i(P(theta_i | Data)) with iterative, gradient based approaches.  These approaches offer computational efficiency, but do not provide a full description of P(theta | Data).  At most they provide the optimization history for each training session."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "We've been playing around with LR as a main algorithm for awhile now.\n",
    "\n",
    "The main benefits of Logistic Regression for us is:\n",
    "\n",
    "- It produces meaningfull probabilities of outcomes P( click | campaign, request ) e [0,1]\n",
    "- It's a simple algorithm (simple, lightweight set of parameters)\n",
    "- Learning is simple and efficient (for local optima)\n",
    "- Prediction, based on learned parameters, is easy to impliment \n",
    "\n",
    "The tools we're using for LR are optimizing logloss, in lieu of P(theta | Data).  Which is a fine proxy for iterative methods.\n",
    "\n",
    "For a bayesian model we'd prefer to learn the posterior distribution over the model parameters.  Typical bayesian linear regression can be easily modeled with a gaussian-gamma model, where the posterior distribution over the model parameters is has a known shape, the gamma distribution.  Logistic Regression, a Generalized Linear Model, models P( y_i | x_i ) = logit(x_i.dot(theta)), where typical linear regression is passes through the logit function mapping (-inf, inf) to [0,1].  If we were to try to compute the posterior distribution over the model parameters, it would go something like this.\n",
    "\n",
    "Logistic function:\n",
    "<img src=\"logisticFunction.png\">\n",
    "\n",
    "Predictive probability:\n",
    "<img src=\"logisticRegessionPredictiveProb.png\">\n",
    "\n",
    "Posterior distribution over the model parameters:\n",
    "<img src=\"logisticRegressionPosteriorDist.png\">\n",
    "\n",
    "Again, bayes formula is made up of three parts.  The poserior on the left, the likelihood on the right in this case, and the prior in the middle.\n",
    "\n",
    "If you take the logarithm of this you get.\n",
    "\n",
    "Log-posterior:\n",
    "<img src=\"logisticRegressionLogPosterior.png\">\n",
    "\n",
    "Now, this looks pretty managable computationally.  We have a few different pieces here, that require some matrix multiplication, but then you just add them all together.\n",
    "\n",
    "- The C in the front is an itegration-constant that we can just ignore if we normalize the function to a distribution.\n",
    "- The Pi_u(theta) part is the prior probability of theta_i, the probability of a single weight vector, under the assumptions we make about what are likely weight vectors (i.e. regularization, or previously learned models).\n",
    "- Then the likelihood for the positive examples.\n",
    "- Lastly, the likelihood for the negative examples.\n",
    "\n",
    "So, like above, we have an equation to evaluate the P(theta_i | Data ) ( or log_P(theta_i | Data ) ).  \n",
    "\n",
    "But what about finding a closed for solution for the whole distribution? \n",
    "\n",
    "The reason bayesian models are hard for Logistic Regression is, there isn't a [conjugate prior](https://en.wikipedia.org/wiki/Conjugate_prior) for the [Logit-Normal distribution](https://en.wikipedia.org/wiki/Logit-normal_distribution).  We know the likelihood of the model has the Logit-Normal shape because we're using categorical variables, and we know are LR parameters have normal-ish distributions.  It's a property of normal distributions, if they are independant, that the sum of several normal distributions is also a normal distribution.  So, the margin or x_i.dot(theta) is normally distributed, and then passed through a logistic function.  Making P(Y | X, theta) ~ Logit-Normal.  \n",
    "\n",
    "In ortherwords, this is an intractable function in that, it can't be easily modeled with known distributions, that have easily computable parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monte Carlo and Particle Filtering\n",
    "\n",
    "\n",
    "For a long time, the way of extimating intractable functions was to generate samples in their range, then pass them through the function.  This process is called [monte carlo estimation](https://en.wikipedia.org/wiki/Monte_Carlo_method).  There are lots of flavors of monte carlo, but they all basically are trying to evaluate a function, over it's range, with some tractable number of samples.  A fast, and often used method for online-learning is Sample-Importance-Resampling, or particle filtering.\n",
    "\n",
    "Particle filtering is online-learning approach to estimating a posterior distribution.  It uses a finite set of \"particles\" or samples within the range of the posterior distribution, and assigns an \"importance\" weight to them by evaluating the particle's value through the posterior distribution function.  An approximation to the Posterior distribution is then computed by normalizing the particles importance weights.  The online-learning part of the model involves using some new data to update the posterior distribution function, and re-generating particles using a sampling strategy utilizing the current generation of particles and their importances.\n",
    "\n",
    "This tool is uses a lot in localization and navigation, and some great, animated examples exist online ([like here](https://www.youtube.com/watch?v=aUkBa1zMKv4)).\n",
    "\n",
    "### In the localization context the elements of particles sampling are:\n",
    "Posterior distribution: The distribution over current location, given history and current data.\n",
    "Particles: Possible locations in space\n",
    "Particle Importance: probability (or log-probability) of being at a particular location, given history and current data.\n",
    "New data: Sensor information (Lidar, radar, gps, cameras and so on)\n",
    "\n",
    "\n",
    "### In the context of a Probability model such as Logistic Regression:\n",
    "Posterior distribution: The distribution over model parameters (for LR the model weights and intercept)\n",
    "Particles: A particular weight vector\n",
    "Particle Importance: Probability (or log-probability) of a particular weight vector, given data\n",
    "New data: Predictions made, and the actual outcomes (for ad-serving, this is impressions serverd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Particle Filtering still suffers from the curse of dimensionality\n",
    "\n",
    "So the question araises, how many particles does one need to do this proceedure?  Well, in localization, a hundred or so samples should be enough to estimate location in a limited size, 2D space.  What about 3D space?  Maybe 10,000 particles would get you about the same coverage of 3D space that 100 particles would get you in 2D space.  Well, what about 4D space, or 5D space?  The answer is \"a lot more\" particles.  Well, what if you're predictive model has 1 million dimensions?  The answer is \"too many\" particles; it's just not do-able.\n",
    "\n",
    "Well, lets put that idea on hold and talk about something else."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensambles and Bagging\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Bagging (Bootstrap aggregation) is a very popular machine learning proceedure used to reduce model variance, and improve performance.  It training k models, from k datasets of size m, each created by sampling, with replacement, the original dataset of size n, where m < n.  The k models then each make their own predictions on new data, and their predictions are combined to produce a meta-prodiction for the whole meta-model.  Often this is combined with boosting, and other sampling rules to make each of the sub-models more havily biased.  In practice, a collection of more biased sub-models, leads to a lower variance overall model.\n",
    "\n",
    "The bootstrap sampling proceedure has been around in the field of statistics for much longer than it has been in machine learning.  It was typically used to estimate confidence bunds for statistics when one is short on data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Ensables as particles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "WIP.\n",
    "\n",
    "Further outline\n",
    "\n",
    "- Weak learners in an ensamble are each a hypothesis vectors in parameter (theta) space.\n",
    "- Generating a bunch of weak learners is equivilant to generating particles in theta space.\n",
    "- Since it is expensive to generate enough random particles to represent a complex theta distribution, we can find candidate thetas by training P weak learners, in a common theta space.  Each weak learner will attempt to find it's own optimal value of theta, ensuring we have better representation of higher likelihood regions of P(theta|data) (the posterior of theta).\n",
    "- We can tune the spread of the ensamble particles (weak learners) with typical ensamble hyper-parameters, such as training on sub-portions of training data, weighting training examples, differing stopping criteria (maximum iterations or tolerance), differing gradient descent hyper-parameters, and so on.\n",
    "\n",
    "- We score the particles using the overall posterior theta distribution.\n",
    "- At prediction time, we can perform Thompson-like sampling by selecting M << P of the weak learners, without replacement.\n",
    "- We can either select them in proportion to their log-likelihood score or we can select them uniformly, and apply their scores as weights towards the overall-prediction\n",
    "- Additionally, we can "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot run multiple SparkContexts at once; existing SparkContext(app=pyspark-shell, master=local[*]) created by <module> at <ipython-input-2-97e7cd2d84d4>:17 ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-97e7cd2d84d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mshellFilePath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspark_home\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'python/pyspark/shell.py'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshellFilePath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshellFilePath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'exec'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/robert.coleman/spark/python/pyspark/shell.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetSystemProperty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"spark.executor.uri\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"SPARK_EXECUTOR_URI\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyFiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madd_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0matexit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/robert.coleman/spark/python/pyspark/context.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \"\"\"\n\u001b[1;32m    111\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callsite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfirst_spark_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mCallSite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgateway\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n",
      "\u001b[0;32m/Users/robert.coleman/spark/python/pyspark/context.py\u001b[0m in \u001b[0;36m_ensure_initialized\u001b[0;34m(cls, instance, gateway)\u001b[0m\n\u001b[1;32m    259\u001b[0m                         \u001b[0;34m\" created by %s at %s:%s \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m                         % (currentAppName, currentMaster,\n\u001b[0;32m--> 261\u001b[0;31m                             callsite.function, callsite.file, callsite.linenum))\n\u001b[0m\u001b[1;32m    262\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m                     \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot run multiple SparkContexts at once; existing SparkContext(app=pyspark-shell, master=local[*]) created by <module> at <ipython-input-2-97e7cd2d84d4>:17 "
     ]
    }
   ],
   "source": [
    "#%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "import math, sys, os\n",
    "from numpy.random import randn\n",
    "from sklearn.datasets import make_blobs\n",
    "import json\n",
    "\n",
    "# setup pyspark for IPython_notebooks\n",
    "os.environ['SPARK_HOME'] = \"/Users/robert.coleman/spark\"\n",
    "spark_home = os.environ.get('SPARK_HOME', None)\n",
    "sys.path.insert(0, spark_home + \"/python\")\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python/lib/py4j-0.8.2.1-src.zip'))\n",
    "shellFilePath = os.path.join(spark_home, 'python/pyspark/shell.py')\n",
    "with open(shellFilePath) as f:\n",
    "    exec(compile(f.read(), shellFilePath, 'exec'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
