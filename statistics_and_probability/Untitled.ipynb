{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from random import choice\n",
    "from bintrees import FastRBTree as RBTree\n",
    "import pyudorandom\n",
    "from itertools import chain\n",
    "\n",
    "class Centroid(object):\n",
    "\n",
    "    def __init__(self, mean, count):\n",
    "        self.mean = float(mean)\n",
    "        self.count = float(count)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"\"\"<Centroid: mean=%.8f, count=%d>\"\"\" % (self.mean, self.count)\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return self.mean == other.mean and self.count == other.count\n",
    "\n",
    "    def update(self, x, weight):\n",
    "        self.count += weight\n",
    "        self.mean += weight * (x - self.mean) / self.count\n",
    "        return\n",
    "\n",
    "\n",
    "class TDigest(object):\n",
    "\n",
    "    def __init__(self, delta=0.01, K=25):\n",
    "        self.C = RBTree()\n",
    "        self.n = 0\n",
    "        self.delta = delta\n",
    "        self.K = K\n",
    "\n",
    "    def __add__(self, other_digest):\n",
    "        data = list(chain(self.C.values(), other_digest.C.values()))\n",
    "        new_digest = TDigest(self.delta, self.K)\n",
    "        \n",
    "        if len(data) > 0:\n",
    "            for c in pyudorandom.items(data):\n",
    "                new_digest.update(c.mean, c.count)\n",
    "\n",
    "        return new_digest\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.C)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"\"\"<T-Digest: n=%d, centroids=%d>\"\"\" % (self.n, len(self))\n",
    "\n",
    "    def _add_centroid(self, centroid):\n",
    "        if centroid.mean not in self.C:\n",
    "            self.C.insert(centroid.mean, centroid)\n",
    "        else:\n",
    "            self.C[centroid.mean].update(centroid.mean, centroid.count)\n",
    "\n",
    "    def _compute_centroid_quantile(self, centroid):\n",
    "        denom = self.n\n",
    "        cumulative_sum = sum(\n",
    "            c_i.count for c_i in self.C.value_slice(-float('Inf'), centroid.mean))\n",
    "        return (centroid.count / 2. + cumulative_sum) / denom\n",
    "\n",
    "    def _update_centroid(self, centroid, x, w):\n",
    "        self.C.pop(centroid.mean)\n",
    "        centroid.update(x, w)\n",
    "        self._add_centroid(centroid)\n",
    "\n",
    "    def _find_closest_centroids(self, x):\n",
    "        try:\n",
    "            ceil_key = self.C.ceiling_key(x)\n",
    "        except KeyError:\n",
    "            floor_key = self.C.floor_key(x)\n",
    "            return [self.C[floor_key]]\n",
    "\n",
    "        try:\n",
    "            floor_key = self.C.floor_key(x)\n",
    "        except KeyError:\n",
    "            ceil_key = self.C.ceiling_key(x)\n",
    "            return [self.C[ceil_key]]\n",
    "\n",
    "        if abs(floor_key - x) < abs(ceil_key - x):\n",
    "            return [self.C[floor_key]]\n",
    "        elif abs(floor_key - x) == abs(ceil_key - x) and (ceil_key != floor_key):\n",
    "            return [self.C[ceil_key], self.C[floor_key]]\n",
    "        else:\n",
    "            return [self.C[ceil_key]]\n",
    "\n",
    "    def _theshold(self, q):\n",
    "        return 4 * self.n * self.delta * q * (1 - q)\n",
    "\n",
    "    def update(self, x, w=1):\n",
    "        \"\"\"\n",
    "        Update the t-digest with value x and weight w.\n",
    "\n",
    "        \"\"\"\n",
    "        self.n += w\n",
    "\n",
    "        if len(self) == 0:\n",
    "            self._add_centroid(Centroid(x, w))\n",
    "            return\n",
    "\n",
    "        S = self._find_closest_centroids(x)\n",
    "\n",
    "        while len(S) != 0 and w > 0:\n",
    "            j = choice(list(range(len(S))))\n",
    "            c_j = S[j]\n",
    "\n",
    "            q = self._compute_centroid_quantile(c_j)\n",
    "\n",
    "            # This filters the out centroids that do not satisfy the second part\n",
    "            # of the definition of S. See original paper by Dunning. \n",
    "            if c_j.count + w > self._theshold(q):\n",
    "                S.pop(j)\n",
    "                continue\n",
    "\n",
    "            delta_w = min(self._theshold(q) - c_j.count, w)\n",
    "            self._update_centroid(c_j, x, delta_w)\n",
    "            w -= delta_w\n",
    "            S.pop(j)\n",
    "\n",
    "        if w > 0:\n",
    "            self._add_centroid(Centroid(x, w))\n",
    "\n",
    "        if len(self) > self.K / self.delta:\n",
    "            self.compress()\n",
    "\n",
    "        return\n",
    "\n",
    "    def batch_update(self, values, w=1):\n",
    "        \"\"\"\n",
    "        Update the t-digest with an iterable of values. This assumes all points have the \n",
    "        same weight.\n",
    "        \"\"\"\n",
    "        for x in values:\n",
    "            self.update(x, w)\n",
    "        self.compress()\n",
    "        return\n",
    "\n",
    "    def compress(self):\n",
    "        T = TDigest(self.delta, self.K)\n",
    "        C = list(self.C.values())\n",
    "        for c_i in pyudorandom.items(C):\n",
    "            T.update(c_i.mean, c_i.count)\n",
    "        self.C = T.C\n",
    "\n",
    "    def percentile(self, p):\n",
    "        \"\"\" \n",
    "        Computes the percentile of a specific value in [0,100].\n",
    "\n",
    "        \"\"\"\n",
    "        if not (0 <= p <= 100):\n",
    "            raise ValueError(\"p must be between 0 and 100, inclusive.\")\n",
    "\n",
    "        t = 0\n",
    "        p = float(p)/100.\n",
    "        p *= self.n\n",
    "\n",
    "        for i, key in enumerate(self.C.keys()):\n",
    "            c_i = self.C[key]\n",
    "            k = c_i.count\n",
    "            if p < t + k:\n",
    "                if i == 0:\n",
    "                    return c_i.mean\n",
    "                elif i == len(self) - 1:\n",
    "                    return c_i.mean\n",
    "                else:\n",
    "                    delta = (self.C.succ_item(key)[1].mean - self.C.prev_item(key)[1].mean) / 2.\n",
    "                return c_i.mean + ((p - t) / k - 0.5) * delta\n",
    "\n",
    "            t += k\n",
    "        return self.C.max_item()[1].mean\n",
    "\n",
    "    def quantile(self, q):\n",
    "        \"\"\" \n",
    "        Computes the quantile of a specific value, ie. computes F(q) where F denotes\n",
    "        the CDF of the distribution. \n",
    "\n",
    "        \"\"\"\n",
    "        t = 0\n",
    "        N = float(self.n)\n",
    "\n",
    "        for i, key in enumerate(self.C.keys()):\n",
    "            c_i = self.C[key]\n",
    "            if i == len(self) - 1:\n",
    "                delta = (c_i.mean - self.C.prev_item(key)[1].mean) / 2.\n",
    "            else:\n",
    "                delta = (self.C.succ_item(key)[1].mean - c_i.mean) / 2.\n",
    "            z = max(-1, (q - c_i.mean) / delta)\n",
    "\n",
    "            if z < 1:\n",
    "                return t / N + c_i.count / N * (z + 1) / 2\n",
    "\n",
    "            t += c_i.count\n",
    "        return 1\n",
    "\n",
    "    def trimmed_mean(self, p1, p2):\n",
    "        \"\"\"\n",
    "        Computes the mean of the distribution between the two percentiles p1 and p2.\n",
    "        This is a modified algorithm than the one presented in the original t-Digest paper. \n",
    "\n",
    "        \"\"\"\n",
    "        if not (p1 < p2):\n",
    "            raise ValueError(\"p1 must be between 0 and 100 and less than p2.\")\n",
    "\n",
    "        s = k = t = 0\n",
    "        p1 /= 100.\n",
    "        p2 /= 100.\n",
    "        p1 *= self.n\n",
    "        p2 *= self.n\n",
    "        for i, key in enumerate(self.C.keys()):\n",
    "            c_i = self.C[key]\n",
    "            k_i = c_i.count\n",
    "            if p1 < t + k_i:\n",
    "                if i == 0:\n",
    "                    delta = self.C.succ_item(key)[1].mean - c_i.mean\n",
    "                elif i == len(self) - 1:\n",
    "                    delta = c_i.mean - self.C.prev_item(key)[1].mean\n",
    "                else:\n",
    "                    delta = (self.C.succ_item(key)[1].mean - self.C.prev_item(key)[1].mean) / 2.\n",
    "                nu = ((p1 - t) / k_i - 0.5) * delta\n",
    "                s += nu * k_i * c_i.mean\n",
    "                k += nu * k_i\n",
    "\n",
    "            if p2 < t + k_i:\n",
    "                return s/k\n",
    "            t += k_i\n",
    "\n",
    "        return s/k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.18603909438\n",
      "0.631299952705\n"
     ]
    }
   ],
   "source": [
    "from numpy import random\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from numpy.random import exponential\n",
    "\n",
    "T1 = TDigest()\n",
    "dist = exponential(25, 1000000)\n",
    "T1.batch_update(dist)\n",
    "print(T1.percentile(25))\n",
    "print(T1.quantile(25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "T1.batch_update(x)\n",
    "\n",
    "print(abs(T1.percentile(50) - 0.5))\n",
    "print(abs(T1.percentile(10) - .1))\n",
    "print(abs(T1.percentile(90) - 0.9))\n",
    "print(abs(T1.percentile(1) - 0.01))\n",
    "print(abs(T1.percentile(0.1) - 0.001))\n",
    "print(T1.trimmed_mean(0.5, 1.))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
