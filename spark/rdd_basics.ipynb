{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /__ / .__/\\_,_/_/ /_/\\_\\   version 1.6.0\n",
      "      /_/\n",
      "\n",
      "Using Python version 2.7.10 (default, Jul 13 2015 12:05:58)\n",
      "SparkContext available as sc, HiveContext available as sqlContext.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "#%load_ext autoreload\n",
    "#%autoreload 2\n",
    "%reload_ext autoreload\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math, sys, os\n",
    "from numpy.random import randn\n",
    "\n",
    "\n",
    "# setup pyspark for IPython_notebooks\n",
    "spark_home = os.environ.get('SPARK_HOME', None)\n",
    "sys.path.insert(0, spark_home + \"/python\")\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python/lib/py4j-0.8.2.1-src.zip'))\n",
    "execfile(os.path.join(spark_home, 'python/pyspark/shell.py'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Top-level RDD methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "RDD = sc.parallelize(range(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collect: \n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "\n",
      "take(15): \n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "\n",
      "takeSample(False,15)\n",
      "[977, 145, 849, 714, 965, 147, 784, 843, 523, 475, 75, 627, 640, 743, 552]\n",
      "\n",
      "isEmpty: \n",
      "False\n",
      "\n",
      "count: \n",
      "1000\n",
      "\n",
      "countApprox(timeout in seconds, confidence interval): \n",
      "1000\n",
      "\n",
      "min, max: \n",
      "0\n",
      "999\n",
      "\n",
      "sum\n",
      "499500\n",
      "\n",
      "mean: \n",
      "499.5\n",
      "\n",
      "meanApprox(timeout in seconds, confidence=0.95): \n",
      "499.5\n",
      "\n",
      "stdev\n",
      "288.674990257\n",
      "\n",
      "variance\n",
      "83333.25\n",
      "\n",
      "histogram(10)\n",
      "bins: \n",
      "[0.0, 99.9, 199.8, 299.70000000000005, 399.6, 499.5, 599.4000000000001, 699.3000000000001, 799.2, 899.1, 999]\n",
      "counts: \n",
      "[100, 100, 100, 100, 100, 100, 100, 100, 100, 100]\n"
     ]
    }
   ],
   "source": [
    "print \"collect: \"\n",
    "print RDD.collect()[:15]\n",
    "\n",
    "print \"\"\n",
    "print \"take(15): \"\n",
    "print RDD.take(15)\n",
    "\n",
    "print \"\"\n",
    "print \"takeSample(False,15)\"\n",
    "print RDD.takeSample(False,15)\n",
    "\n",
    "print \"\"\n",
    "print \"isEmpty: \"\n",
    "print RDD.isEmpty()\n",
    "\n",
    "print \"\"\n",
    "print \"count: \"\n",
    "print RDD.count()\n",
    "\n",
    "print \"\"\n",
    "print \"countApprox(timeout in seconds, confidence interval): \"\n",
    "print RDD.countApprox(1,0.95)\n",
    "\n",
    "print \"\"\n",
    "print \"min, max: \"\n",
    "print RDD.min()\n",
    "print RDD.max()\n",
    "\n",
    "print \"\"\n",
    "print \"sum\"\n",
    "print RDD.sum()\n",
    "\n",
    "print \"\"\n",
    "print \"mean: \"\n",
    "print RDD.mean()\n",
    "\n",
    "print \"\"\n",
    "print \"meanApprox(timeout in seconds, confidence=0.95): \"\n",
    "print RDD.meanApprox(1, confidence=0.95)\n",
    "\n",
    "print \"\"\n",
    "print \"stdev\"\n",
    "print RDD.stdev()\n",
    "\n",
    "print \"\"\n",
    "print \"variance\"\n",
    "print RDD.variance()\n",
    "\n",
    "\n",
    "print \"\"\n",
    "print \"histogram(10)\"\n",
    "bins, counts = RDD.histogram(10)\n",
    "print \"bins: \"\n",
    "print bins\n",
    "print \"counts: \"\n",
    "print counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Higher-Order Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RDD.filter( lambda x: x > 990).collect()\n",
      "[991, 992, 993, 994, 995, 996, 997, 998, 999]\n",
      "\n",
      "RDD.map(lambda x: x % 4).take(10)\n",
      "[0, 1, 2, 3, 0, 1, 2, 3, 0, 1]\n",
      "\n",
      "RDD.reduce(lambda a, b: min(a, b))\n",
      "0\n",
      "RDD.reduce(lambda a, b: max(a, b))\n",
      "999\n",
      "\n",
      "RDD.filter(lambda x: x == 2).collect()\n",
      "[4]\n",
      "RDD.flatMap(lambda x: [x] * (x % 5)).filter(lambda x: x == 4).collect()\n",
      "[4, 4, 4, 4]\n"
     ]
    }
   ],
   "source": [
    "# fitler\n",
    "print \"RDD.filter( lambda x: x > 990).collect()\"\n",
    "print RDD.filter( lambda x: x > 990).collect()\n",
    "\n",
    "print \"\"\n",
    "print \"RDD.map(lambda x: x % 4).take(10)\"\n",
    "print RDD.map(lambda x: x % 4).take(10)\n",
    "\n",
    "print \"\"\n",
    "print \"RDD.reduce(lambda a, b: min(a, b))\"\n",
    "print RDD.reduce(lambda a, b: min(a, b))\n",
    "print \"RDD.reduce(lambda a, b: max(a, b))\"\n",
    "print RDD.reduce(lambda a, b: max(a, b))\n",
    "\n",
    "print \"\"\n",
    "print \"RDD.filter(lambda x: x == 2).collect()\"\n",
    "print RDD.filter(lambda x: x == 4).collect()\n",
    "print \"RDD.flatMap(lambda x: [x] * (x % 5)).filter(lambda x: x == 4).collect()\"\n",
    "print RDD.flatMap(lambda x: [x] * (x % 5)).filter(lambda x: x == 4).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RDD interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "\n",
      "[('a', 0), ('b', 1), ('c', 2), ('d', 3), ('e', 4), ('f', 5), ('g', 6), ('h', 7), ('i', 8), ('j', 9), ('k', 10), ('l', 11), ('m', 12), ('n', 13), ('o', 14), ('p', 15), ('q', 16), ('r', 17), ('s', 18), ('t', 19), ('u', 20), ('v', 21), ('w', 22), ('x', 23), ('y', 24), ('z', 25)]\n",
      "\n",
      "RDD.collect() == zip(alpha,range(26))\n",
      "True\n",
      "\n",
      "cartesian RDD size: \n",
      "676\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "alpha = string.ascii_lowercase\n",
    "num_RDD = sc.parallelize(range(26))\n",
    "alpha_RDD = sc.parallelize(alpha)\n",
    "\n",
    "# zipping two rdds\n",
    "alpha_num_RDD = alpha_RDD.zip(num_RDD)\n",
    "\n",
    "print alpha_RDD.collect()\n",
    "print \"\"\n",
    "print num_RDD.collect()\n",
    "print \"\"\n",
    "print alpha_num_RDD.collect()\n",
    "print \"\"\n",
    "print \"RDD.collect() == zip(alpha,range(26))\"\n",
    "print alpha_num_RDD.collect() == zip(alpha,range(26))\n",
    "\n",
    "# cartesian product RDD\n",
    "# for every item in A pair with every item in B.\n",
    "# For RDDs of size N and M produces a new RDD of size N*M\n",
    "print \"\"\n",
    "cart_RDD = alpha_RDD.cartesian(num_RDD)\n",
    "print \"cartesian RDD size: \"\n",
    "print cart_RDD.count()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A = sc.parallelize([('x', 1), ('y', 4), ('y', 5), ('x', 2)])\n",
      "B = sc.parallelize([('x', 2), ('y', 5), ('z', 6)])\n",
      "\n",
      "A.union(B).collect()\n",
      "[('x', 1), ('x', 2), ('x', 2), ('y', 4), ('y', 5), ('y', 5), ('z', 6)]\n",
      "\n",
      "union (distict)\n",
      "A.union(B).distinct().collect()\n",
      "[('x', 1), ('x', 2), ('y', 4), ('y', 5), ('z', 6)]\n",
      "\n",
      "intersection\n",
      "A.intersection(B).collect()\n",
      "[('x', 2), ('y', 5)]\n",
      "\n",
      "subtract (set difference)\n",
      "A.subtract(B).collect()\n",
      "[('x', 1), ('y', 4)]\n"
     ]
    }
   ],
   "source": [
    "print \"A = sc.parallelize([('x', 1), ('y', 4), ('y', 5), ('x', 2)])\"\n",
    "print \"B = sc.parallelize([('x', 2), ('y', 5), ('z', 6)])\"\n",
    "A = sc.parallelize([(\"x\", 1), (\"y\", 4), (\"y\", 5), (\"x\", 2)])\n",
    "B = sc.parallelize([(\"x\", 2), (\"y\", 5), (\"z\", 6)])\n",
    "\n",
    "print \"\"\n",
    "print \"A.union(B).collect()\"\n",
    "print sorted(A.union(B).collect())\n",
    "\n",
    "print \"\"\n",
    "print \"union (distict)\"\n",
    "print \"A.union(B).distinct().collect()\"\n",
    "print sorted(A.union(B).distinct().collect())\n",
    "\n",
    "print \"\"\n",
    "print \"intersection\"\n",
    "print \"A.intersection(B).collect()\"\n",
    "print sorted(A.intersection(B).collect())\n",
    "\n",
    "print \"\"\n",
    "print \"subtract (set difference)\"\n",
    "print \"A.subtract(B).collect()\"\n",
    "print sorted(A.subtract(B).collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key-Value basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyBy\n",
      "RDD.keyBy(lambda x: x % 5).take(10)\n",
      "[(0, 0), (1, 1), (2, 2), (3, 3), (4, 4), (0, 5), (1, 6), (2, 7), (3, 8), (4, 9)]\n",
      "\n",
      "keys\n",
      "RDD.keyBy(lambda x: x % 5).keys().distinct().count()\n",
      "5\n",
      "\n",
      "values\n",
      "RDD.keyBy(lambda x: x % 5).values().distinct().count()\n",
      "1000\n",
      "\n",
      "collectAsMap \n",
      "alpha_num_RDD.collectAsMap()\n",
      "{'a': 0, 'c': 2, 'b': 1, 'e': 4, 'd': 3, 'g': 6, 'f': 5, 'i': 8, 'h': 7, 'k': 10, 'j': 9, 'm': 12, 'l': 11, 'o': 14, 'n': 13, 'q': 16, 'p': 15, 's': 18, 'r': 17, 'u': 20, 't': 19, 'w': 22, 'v': 21, 'y': 24, 'x': 23, 'z': 25}\n",
      "\n",
      "countByKey\n",
      "dict(cart_RDD.countByKey())\n",
      "{'a': 26, 'c': 26, 'b': 26, 'e': 26, 'd': 26, 'g': 26, 'f': 26, 'i': 26, 'h': 26, 'k': 26, 'j': 26, 'm': 26, 'l': 26, 'o': 26, 'n': 26, 'q': 26, 'p': 26, 's': 26, 'r': 26, 'u': 26, 't': 26, 'w': 26, 'v': 26, 'y': 26, 'x': 26, 'z': 26}\n",
      "\n",
      "reduceByKey\n",
      "RDD.keyBy(lambda x: x % 5).reduceByKey(lambda a, b: max(a,b)).collectAsMap()\n",
      "{0: 995, 1: 996, 2: 997, 3: 998, 4: 999}\n"
     ]
    }
   ],
   "source": [
    "print \"keyBy\"\n",
    "print \"RDD.keyBy(lambda x: x % 5).take(10)\"\n",
    "print RDD.keyBy(lambda x: x % 5).take(10)\n",
    "\n",
    "print \"\"\n",
    "print \"keys\"\n",
    "print \"RDD.keyBy(lambda x: x % 5).keys().distinct().count()\"\n",
    "print RDD.keyBy(lambda x: x % 5).keys().distinct().count()\n",
    "\n",
    "print \"\"\n",
    "print \"values\"\n",
    "print \"RDD.keyBy(lambda x: x % 5).values().distinct().count()\"\n",
    "print RDD.keyBy(lambda x: x % 5).values().distinct().count()\n",
    "\n",
    "print \"\"\n",
    "print \"collectAsMap \"\n",
    "print \"alpha_num_RDD.collectAsMap()\"\n",
    "print alpha_num_RDD.collectAsMap()\n",
    "\n",
    "print \"\"\n",
    "print \"countByKey\"\n",
    "print \"dict(cart_RDD.countByKey())\"\n",
    "print dict(cart_RDD.countByKey())\n",
    "\n",
    "print \"\"\n",
    "print \"reduceByKey\"\n",
    "print \"RDD.keyBy(lambda x: x % 5).reduceByKey(lambda a, b: max(a,b)).collectAsMap()\"\n",
    "print RDD.keyBy(lambda x: x % 5).reduceByKey(lambda a, b: max(a,b)).collectAsMap()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
