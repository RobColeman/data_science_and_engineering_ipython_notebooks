{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outline\n",
    "\n",
    "An exploration strategy I have proposed involves choosing an order for scored campaigns by sampling from the distribution of predicted reward for the candidate advertising campaigns-targets.  \n",
    "\n",
    "“Reward” is a term often used to describe the benefit from an action in the mutli-armed bandit problem.  In our case, “predicted reward” is referring to the algorithm predicted eCPM for a advertising campaigns-target pair.  \n",
    "\n",
    "In words, the procedure is to treat the set of eCPMs as the elements of a multinomial, and sample from that distribution without replacement. By doing so, we will generate a new, randomized, order for the scored, candidate campaign-targets, where the expected value of the distributions of the relative elements, will retain the same order as the prediced reward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The algorithm\n",
    "\n",
    "In pseudo-code, the inefficient, but direct form of the algorithm is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nalpha = a parameter used to make the algorithm more or less greedy (higher is more greedy)\\nN = number of candidate campaigns\\nL = list of scored, candidate campaigns\\nO = output, re-ordered, scored, candidate campaigns\\n\\nscaledL = for each campaign, raise the eCPM to eCPM ^ alpha\\n\\nnormL = normalize the list of scaledL (where we devide each eCPM ^ alpha by the sum of them all)\\n\\ncumNormL = perform a cumulative sum from the start to the end of the \\n            normalized list of scored, candidate campaigns \\n            (the first campaigns cumEcpm will be 0, while the last will be 1 - it's normed ecpm)\\n\\nwhile (N > 0) do\\n    compute normL from current elements of L\\n    compute cumNorm from normL\\n    i = rand(0,1)\\n    for j in range 0 to length of cumNormL:\\n        if i > cumNormL(j):\\n            append cumNormL(j) to the tail of O\\n            remove the jth element from L\\n            N -= 1\\n            break\\n        else:\\n            continue\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "alpha = a parameter used to make the algorithm more or less greedy (higher is more greedy)\n",
    "N = number of candidate campaigns\n",
    "L = list of scored, candidate campaigns\n",
    "O = output, re-ordered, scored, candidate campaigns\n",
    "\n",
    "scaledL = for each campaign, raise the eCPM to eCPM ^ alpha\n",
    "\n",
    "normL = normalize the list of scaledL (where we devide each eCPM ^ alpha by the sum of them all)\n",
    "\n",
    "cumNormL = perform a cumulative sum from the start to the end of the \n",
    "            normalized list of scored, candidate campaigns \n",
    "            (the first campaigns cumEcpm will be 0, while the last will be 1 - it's normed ecpm)\n",
    "\n",
    "while (N > 0) do\n",
    "    compute normL from current elements of L\n",
    "    compute cumNorm from normL\n",
    "    i = rand(0,1)\n",
    "    for j in range 0 to length of cumNormL:\n",
    "        if i > cumNormL(j):\n",
    "            append cumNormL(j) to the tail of O\n",
    "            remove the jth element from L\n",
    "            N -= 1\n",
    "            break\n",
    "        else:\n",
    "            continue\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A more efficient, memoized approach\n",
    "\n",
    "When streams or generators are suppored, that would also be preferable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from random import random as rand\n",
    "\n",
    "Campaign = namedtuple('Campaign', ['id', 'ecpm'])\n",
    "\n",
    "class Sampler:\n",
    "    \n",
    "    def __init__(self, campaigns, alpha = 1.0):\n",
    "        self.remaining_campaigns = {}\n",
    "        self.total_sum = 0\n",
    "        for c in campaigns:\n",
    "            scaled_ecpm = c.ecpm ** alpha\n",
    "            self.ramaining_campaigns[c.id] = (scaled_ecpm, c)\n",
    "            self.total_sum += scaled_ecpm\n",
    "    \n",
    "    def size(self):\n",
    "        return len(self.ramaining_campaigns)\n",
    "    \n",
    "    def rand(self):\n",
    "        return rand() * self.total_sum\n",
    "    \n",
    "    def get_next_sample_id(self):\n",
    "        lastCumSum = 0.0\n",
    "        i = this.rand()\n",
    "        for cid, t in self.ramaining_campaigns.items():\n",
    "            if t[0] >= i:\n",
    "                return cid\n",
    "        \n",
    "    def pop(self, cid):\n",
    "        self.n -= 1\n",
    "        self.totalSum -= self.remaining_campaigns[cid][0]\n",
    "        return self.remaining_campaigns.pop(cid)\n",
    "    \n",
    "    def get_next_sample(self):\n",
    "        if self.size() > 0:\n",
    "            next_cid = get_next_sample_id()\n",
    "            return pop(next_cid)\n",
    "        else:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
